20 Newsgroups, kkt = 0.5. Unlabeled sets have the same P:N ratio as the Labeled set. Redux sets also have this same ratio. Test set has the same ratio as well:

Augmenting with Bayesian sets:

1st redux:    0.9375    0.0085    0.0169
aug           0.4366    0.9778    0.6037
2nd redux:    0.9756    0.0228    0.0445
aug	      0.4353    0.9727    0.6014
3rd redux     0.5461    0.9704    0.6989
aug	      0.3742    0.9949    0.5439
full train:   0.4984    0.9858    0.6621

Augmenting with S-EM algo:

1st redux:    0.9375    0.0085    0.0169
aug    	      0.3460    0.9966    0.5136
2nd redux:    0.9756    0.0228    0.0445
aug           0.2870    1.0000    0.4461
3rd redux:    0.5461    0.9704    0.6989
aug    	      0.3994    0.9983    0.5705
full train:   0.4984    0.9858    0.6621

Precision, recall and fscore of the entity set expansion used to get aug:

bayes1:    0.7593    0.8463    0.8004
sem1:      0.7775    0.8666    0.8196
         
bayes2:    0.6777    0.8931    0.7706
sem2:      0.6761    0.8910    0.7688
         
bayes3:    0.3263    0.9456    0.4851
sem3:      0.3251    0.9421    0.4833

We are using Bayes to extract exactly as many positives as with SEM, using SEM's number as the cutoff. We can see that they perform in a very similar way here (questioning the claim that SEM is the superior approach).

20 Newsgroups, kkt = 0.1, same P:N ratio in all training data:

Augmenting with bayes:

redux1:        0.9547    0.2641    0.4137
aug:           0.9860    0.0803    0.1484
redux2:        1.0000    0.0028    0.0057
aug:           0.7047    0.9289    0.8014
redux3:        0.7161    0.9317    0.8098
aug:           0.6208    0.9596    0.7539
full train:    0.7542    0.9118    0.8256


Augmenting with SEM:

redux1:       0.9547    0.2641    0.4137
aug:          0.9809    0.0876    0.1609
redux2:       1.0000    0.0028    0.0057
aug:          0.7101    0.9311    0.8057
redux3:       0.7161    0.9317    0.8098
aug:          0.6071    0.9664    0.7457
full train:   0.7542    0.9118    0.8256


Precision, recall and fscore of the entity set expansion used to get aug:

bayes:    0.7558    0.8631    0.8059
sem:      0.7681    0.8771    0.8190

bayes:    0.6543    0.9031    0.7588
sem:      0.6619    0.9136    0.7676

bayes:    0.2737    0.9632    0.4262
sem:      0.2672    0.9404    0.4161


20 Newsgroups, kkt = 0.9 ( to get less overfitting, but a terrible classifier, for redux1/2), same ratios in test, train, redux:

Augmenting with Bayes:

redux1:        1.0000    0.0023    0.0045
aug:           0.9762    0.0233    0.0456
redux2:        0.3301    0.9829    0.4943
aug:           0.2847    1.0000    0.4432
redux3:        0.2848    0.9892    0.4422
aug:           0.3181    0.9954    0.4822
full train:    0.2860    0.9960    0.4444

Augmenting with SEM:

redux1:      1.0000    0.0023    0.0045
aug:         0.8642    0.0398    0.0762
redux2:      0.3301    0.9829    0.4943
aug:         0.2904    0.9989    0.4500
redux3:      0.2848    0.9892    0.4422
aug:         0.2883    0.9994    0.4475
full train:  0.2860    0.9960    0.4444

Precision, recall and fscore of the entity set expansion used to get aug:


bayes:    0.7609    0.8526    0.8041
sem:      0.7772    0.8709    0.8214

bayes:    0.6585    0.9062    0.7628
sem:      0.6608    0.9094    0.7654

bayes:    0.2730    0.9737    0.4264
sem:      0.2646    0.9439    0.4134


The drop in performance for 33% when ktt = 0.5/0.1 is not a bug; verifier independently: for kkt = 0.1(similar to 0.5, 0.9):

10%:    0.8090    0.6727    0.7346
33% :    0.9500    0.0108    0.0214, with  sum(TrainLabels(sampler)) / 3300 = 0.2942, which is approx the same as 28% in overall.

When kkt = 0.9, the classifier is so bad that extra data doesn't help much at all. That's why, apart from augmenting (the terrible) redux1, it makes only marginal improvement in the rest of them.

Since the distribution is the same and Reuters is a more interesting dataset, we'll leave ( at least for now), the examination of sample bias performance for Reuters data set.


Reuters, first two classes used, second used as positive:
kkt = 0.5:
ResultsSVM =

    0.9421    0.6032    0.7355
    0.9547    0.7823    0.8599
    0.9571    0.9000    0.9277
    0.9608    0.9081    0.9337
    0.3795    0.9758    0.5465
    0.3983    0.9952    0.5689
         0         0         0
    0.3806    0.9694    0.5466
    0.3933    0.9806    0.5614
         0         0         0
    0.8516    0.1758    0.2914
         0         0         0
         0         0         0



ResultsSVM =
kkt = 0.1
    0.9256    0.6419    0.7581
    0.9460    0.8194    0.8781
    0.9492    0.8742    0.9102
    0.9601    0.8935    0.9256
    0.4103    0.8887    0.5614
    0.8268    0.9855    0.8992
         0         0         0
    0.5667    0.8774    0.6886
    0.8669    0.9242    0.8946
         0         0         0
    0.8034    0.5403    0.6461
         0         0         0
         0         0         0

Reuters with first two classes, positive class is class 2 from original, negative one is one.

Running with kkt = 0.5

BayesQ =

    0.9400    0.6065    0.7373
    0.3788    0.9629    0.5437
    0.9426    0.7677    0.8462
    0.3975    0.9823    0.5660
    0.9529    0.9129    0.9325
    0.6827    0.8468    0.7559
    0.9608    0.9081    0.9337

In data sparse applications, it still improves recall substantially, even above the use of full data(makes sense, less negatives). However, in this case, it degraded the overall performance of all...

SemQ =

    0.9400    0.6065    0.7373
    0.4219    0.9984    0.5932
    0.9426    0.7677    0.8462
    0.3739    1.0000    0.5443
    0.9529    0.9129    0.9325
    0.9039    0.9258    0.9147
    0.9608    0.9081    0.9337

The same can be said of SEM, but to a smaller extent - it peforms significantly better in redux80, not degrading the performance that much. Futhermore, the recall achieved with 10 and 33 is amazing, but probably means that it just skewed the set more than is should have.

entitySetQ =

    0.6636    1.0000    0.7978
    0.6626    0.9985    0.7965
         0         0         0
    0.5902    1.0000    0.7423
    0.5896    0.9990    0.7415
         0         0         0
    0.2819    1.0000    0.4398
    0.2819    1.0000    0.4398

In the overall entity set expansion, their perfomance is again so close that it's actually amazing that the differences achieved in subsequent augmentation are so stark.

Reuters, kkt = 0.9

>> BayesQ

    0.9538    0.7000    0.8074
    0.4078    0.9919    0.5780
    0.9288    0.9468    0.9377
    0.3771    0.9677    0.5427
    0.9218    0.9694    0.9450
    0.3761    0.9742    0.5427
    0.9316    0.9661    0.9485

SemQ =

    0.9538    0.7000    0.8074
    0.3950    0.9919    0.5650
    0.9288    0.9468    0.9377
    0.3741    0.9871    0.5426
    0.9218    0.9694    0.9450
    0.3698    0.9806    0.5371
    0.9316    0.9661    0.9485

>> entitySetQ

entitySetQ =

    0.6636    1.0000    0.7978
    0.6626    0.9985    0.7965
         0         0         0
    0.5862    1.0000    0.7391
    0.5856    0.9990    0.7384
         0         0         0
    0.2819    1.0000    0.4398
    0.2819    1.0000    0.4398

With these "bad" classifiers, which are actually performing amazingly well on this dataset(probably meaning that it's quite easy), both methods are failing outright - they are too liberal in adding new positives, which works against the SVM. Furthermore, their entity set expansion success is identical!



Reuters, kkt = 0.1: 


BayesQ =

    0.9525    0.6790    0.7928
    0.4762    0.8887    0.6201
    0.9488    0.8065    0.8718
    0.5673    0.8839    0.6910
    0.9582    0.8871    0.9213
    0.7766    0.8581    0.8153
    0.9601    0.8935    0.9256

>> SemQ

SemQ =

    0.9525    0.6790    0.7928
    0.7707    0.9919    0.8674
    0.9488    0.8065    0.8718
    0.8904    0.9565    0.9222
    0.9582    0.8871    0.9213
    0.9265    0.8742    0.8996
    0.9601    0.8935    0.9256

>> entitySetQ

entitySetQ =

    0.6636    1.0000    0.7978
    0.6626    0.9985    0.7965
         0         0         0
    0.5866    1.0000    0.7394
    0.5854    0.9979    0.7379
         0         0         0
    0.2816    1.0000    0.4395
    0.2816    1.0000    0.4395

KKD dataset, kktthreshold = 0.1:
BayesQ =

    0.1429    0.0067    0.0127
    0.1818    0.1200    0.1446
    0.1579    0.0200    0.0355
    0.1667    0.1133    0.1349
    0.1905    0.0267    0.0468
    0.1649    0.1067    0.1296
    0.2941    0.0333    0.0599

>> SemQ

SemQ =

    0.1429    0.0067    0.0127
         0         0       NaN
    0.1579    0.0200    0.0355
    0.1183    0.0733    0.0905
    0.1905    0.0267    0.0468
    0.1348    0.0800    0.1004
    0.2941    0.0333    0.0599

>> entitySetQ

entitySetQ =

    0.2300    0.6053    0.3333
    0.2700    0.7105    0.3913
         0         0         0
    0.1684    0.5517    0.2581
    0.2000    0.6552    0.3065
         0         0         0
    0.0854    0.7778    0.1538
    0.0854    0.7778    0.1538

KDD dataset, threshold for kkt = 0.9

BayesQ =

    0.1111    0.0067    0.0126
    0.2143    0.1800    0.1957
    0.2500    0.0267    0.0482
    0.2366    1.0000    0.3827
    0.3571    0.0333    0.0610
    0.1707    0.0933    0.1207
       NaN         0       NaN

All classified as zero, so this is exactly where data augmentation should help the most! We achieve orders of magnitutes improvement!!

>> SemQ

SemQ =

    0.1111    0.0067    0.0126
    0.2143    0.1800    0.1957
    0.2500    0.0267    0.0482
    0.2366    1.0000    0.3827
    0.3571    0.0333    0.0610
         0         0       NaN
       NaN         0       NaN

>> entitySetQ

entitySetQ =

    0.2637    0.6316    0.3721
    0.2857    0.6842    0.4031
         0         0         0
    0.1939    0.6552    0.2992
    0.2245    0.7586    0.3465
         0         0         0
    0.0602    0.5556    0.1087
    0.0723    0.6667    0.1304

kkt = 0.6

BayesQ =

         0         0       NaN
    0.1667    0.0533    0.0808
       NaN         0       NaN
         0         0       NaN
       NaN         0       NaN
    0.1474    0.0933    0.1143
       NaN         0       NaN

>> SemQ

SemQ =

         0         0       NaN
    0.1373    0.0933    0.1111
       NaN         0       NaN
    0.1282    0.0667    0.0877
       NaN         0       NaN
    0.1205    0.0667    0.0858
       NaN         0       NaN

>> entitySetQ

entitySetQ =

    0.1364    0.3158    0.1905
    0.2841    0.6579    0.3968
         0         0         0
    0.2174    0.6897    0.3306
    0.2391    0.7586    0.3636
         0         0         0
    0.0488    0.4444    0.0879
    0.0610    0.5556    0.1099


kkt = 0.1, bias = 0.3 - leading to use of 1, 3, 10 positives in turn for the reduxes

BayesQ

BayesQ =

       NaN         0       NaN
         0         0       NaN
       NaN         0       NaN
    0.2333    0.0467    0.0778
    0.2222    0.0133    0.0252
    0.2017    0.1600    0.1784
       NaN         0       NaN

>> SemQ

SemQ =

       NaN         0       NaN
    0.1385    0.0600    0.0837
       NaN         0       NaN
    0.1190    0.0667    0.0855
    0.2222    0.0133    0.0252
    0.1548    0.0867    0.1111
       NaN         0       NaN

>> entitySetQ

entitySetQ =

         0         0       NaN
    0.2979    0.6829    0.4148
         0         0         0
    0.2474    0.6316    0.3556
    0.2680    0.6842    0.3852
         0         0         0
    0.2211    0.6364    0.3281
    0.2526    0.7273    0.3750




KKT = 0.1, Reuters, bidirectional pull:

ResultsBayes =

    0.9631    0.6742    0.7932
    0.4512    0.8726    0.5948
    0.9331    0.7871    0.8539
    0.5827    0.8919    0.7049
    0.9545    0.8790    0.9152
    0.8245    0.8790    0.8509
    0.9601    0.8935    0.9256


ResultsSEM =

    0.9631    0.6742    0.7932
    0.8338    0.9871    0.9040
    0.9331    0.7871    0.8539
    0.8569    0.9371    0.8952
    0.9545    0.8790    0.9152
    0.9248    0.9129    0.9188
    0.9601    0.8935    0.9256


ResultsRocSVM =

    0.9631    0.6742    0.7932
    0.9602    0.7774    0.8592
    0.9331    0.7871    0.8539
    0.9316    0.8129    0.8682
    0.9545    0.8790    0.9152
    0.9430    0.9065    0.9243
    0.9601    0.8935    0.9256


entitySetExpansionQuality =

    0.6618    0.9923    0.7941
    0.6608    0.9907    0.7928
    1.0000    0.0673    0.1262
    0.5918    0.9948    0.7421
    0.5915    0.9948    0.7419
    0.9400    0.2443    0.3878
    0.2815    0.9895    0.4383
    0.2829    0.9965    0.4407
    0.8615    0.7805    0.8190